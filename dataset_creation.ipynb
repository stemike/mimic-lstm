{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stemike/mimic-lstm/blob/master/dataset_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY542Q4U8J4g",
        "outputId": "b5671dfb-4781-4875-c643-a55a32feef54"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_WWIFIiWOZ4"
      },
      "source": [
        "import cv2\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from glob import glob"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma5ybdsq8QP0"
      },
      "source": [
        "# constants\n",
        "drive_path = '/content/drive/My Drive'\n",
        "user_path = '/JKU/CV'\n",
        "project_path = '/CV_Project/Dataset/data_WiSAR/data/'\n",
        "impath = drive_path + user_path + project_path\n",
        "\n",
        "data_folders = ['train/', 'validation/', 'test/']\n",
        "mask_path = impath + 'mask.png'\n",
        "homography_name = 'homographies.json'\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) # Grayscale mask"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm4iqbbbU7ug",
        "outputId": "43182adf-ee25-4e97-9e4b-fb58c011ffa5"
      },
      "source": [
        "# Get an overview of the amount of data\n",
        "for data_folder in data_folders:\n",
        "  samples = glob(f'{impath + data_folder}/*/')\n",
        "  print(f'{len(samples)} samples in {data_folder}')\n",
        "  n_images = [len(glob(f'{sample}/*.png')) for sample in samples]\n",
        "  print(f'Average of {np.mean(n_images)} images with std of {np.std(n_images)} per sample in {data_folder}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26 samples in train/\n",
            "Average of 70.0 images with std of 0.0 per sample in train/\n",
            "11 samples in validation/\n",
            "Average of 70.0 images with std of 0.0 per sample in validation/\n",
            "13 samples in test/\n",
            "Average of 70.0 images with std of 0.0 per sample in test/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QadMDIYaCwws"
      },
      "source": [
        "def merge_cameras(image_paths, homographies, mask=None):\n",
        "  \"\"\"\n",
        "  Merges the 10 cameras of a sample into one image\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  for image_path in image_paths:\n",
        "    # Extracts the file name from full path. \n",
        "    image_key = image_path.split('/')[-1].split('.')[0]\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    if mask is not None:\n",
        "      image = cv2.bitwise_and(image, image, mask = mask)\n",
        "    homography = np.array(homographies[image_key])\n",
        "    warped_image = cv2.warpPerspective(image, homography, image.shape[:2])\n",
        "    images.append(warped_image)\n",
        "  \n",
        "  return np.mean(images, axis=0)\n",
        "\n",
        "def draw_boxes_on_val_image(image, sample_name, bb_path, show_small=True):\n",
        "  \"\"\"\n",
        "  Draws the ground truth boxes on an image\n",
        "  \"\"\"\n",
        "  with open(bb_path, 'r') as f:\n",
        "    gtlabels = json.load(f)\n",
        "\n",
        "  for bb in gtlabels[sample_name]:\n",
        "    x,y,w,h = bb\n",
        "    image = cv2.rectangle(image,(x, y),(x+w, y+h),(0,0,255),5)\n",
        "  \n",
        "  if show_small:\n",
        "    image = cv2.resize(image, (500, 500))\n",
        "\n",
        "  cv2_imshow(image)\n",
        "\n",
        "def prepare_dataset(data_folder, homography_name, show_images=False, n_max_frame=7):\n",
        "  \"\"\"\n",
        "  Returns an array of shape N_Sample x N_Frames X Image_Shape\n",
        "  \"\"\"\n",
        "  print(data_folder)\n",
        "  samples = []\n",
        "  for sample in sorted(glob(f'{data_folder}/*/')):\n",
        "    homography_path = f'{sample}{homography_name}'\n",
        "    with open(homography_path, 'r') as f:\n",
        "      homographies = json.load(f)\n",
        "    sample_frames = []\n",
        "\n",
        "    print(f'\\r{sample}', end='')\n",
        "\n",
        "    for frame in range(n_max_frame):\n",
        "      images = []\n",
        "      image_paths = glob(f'{sample}/{frame}-*.png')\n",
        "\n",
        "      image = merge_cameras(image_paths, homographies, mask)\n",
        "      \n",
        "      if frame == 0 and show_images:\n",
        "        if 'validation' in data_folder:\n",
        "          bb_path = f'{data_folder}/labels.json'\n",
        "          sample_name = sample.split('/')[-2]\n",
        "          draw_boxes_on_val_image(image, sample_name, bb_path, show_small=True)\n",
        "        else:\n",
        "          image_small = cv2.resize(image, (500, 500))\n",
        "          cv2_imshow(image_small)\n",
        "      \n",
        "      sample_frames.append(image)\n",
        "    samples.append(np.array(sample_frames))\n",
        "  print()\n",
        "  return np.array(samples)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnDaDM8SiQ2A",
        "outputId": "3410ff7b-0449-4a18-e079-5633b9b8f491"
      },
      "source": [
        "for data_folder in data_folders:\n",
        "  set_name = data_folder.split('/')[-2]\n",
        "  np_dataset = prepare_dataset(impath + data_folder, homography_name)\n",
        "  print(np_dataset.shape, end=' to ')\n",
        "  np_dataset = np_dataset.reshape(-1, np_dataset.shape[-3], np_dataset.shape[-2], np_dataset.shape[-1])\n",
        "  print(np_dataset.shape)\n",
        "  labels = torch.ones(np_dataset.shape[0])\n",
        "  tensor_dataset = torch.utils.data.TensorDataset(torch.Tensor(np_dataset), labels)\n",
        "  \n",
        "  with open(f'{impath}{set_name}.pickle', 'wb') as f:\n",
        "    print(f'Saved to dataset to {impath}{set_name}.pickle')\n",
        "    pickle.dump(tensor_dataset, f)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/train/\n",
            "/content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/train/train-2-9/\n",
            "(26, 7, 1024, 1024, 3) to (182, 1024, 1024, 3)\n",
            "Saved to dataset to /content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/train.pickle\n",
            "/content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/validation/\n",
            "/content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/validation/valid-2-3/\n",
            "(11, 7, 1024, 1024, 3) to (77, 1024, 1024, 3)\n",
            "Saved to dataset to /content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/validation.pickle\n",
            "/content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/test/\n",
            "/content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/test/test-2-8/\n",
            "(13, 7, 1024, 1024, 3) to (91, 1024, 1024, 3)\n",
            "Saved to dataset to /content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/test.pickle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcscq4CAiNKz",
        "outputId": "174e683e-2258-479d-875e-083319d45bad"
      },
      "source": [
        "show_pictures = False\n",
        "if show_pictures:\n",
        "  prepare_dataset(impath + data_folders[1], homography_name, show_images=True)\n",
        "  print()\n",
        "else:\n",
        "  load_path = f'{impath}train.pickle'\n",
        "  with open(load_path, 'rb') as f:\n",
        "    print(f'Loading file from: {load_path}')\n",
        "    ds = pickle.load(f, encoding= 'unicode_escape') \n",
        "    print(ds)\n",
        "  dl = torch.utils.data.DataLoader(ds, batch_size=16)\n",
        "  print(dl)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file from: /content/drive/My Drive/JKU/CV/CV_Project/Dataset/data_WiSAR/data/train.pickle\n",
            "<torch.utils.data.dataset.TensorDataset object at 0x7fc2bf9034d0>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7fc3c6cac2d0>\n"
          ]
        }
      ]
    }
  ]
}