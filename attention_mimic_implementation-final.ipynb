{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from rnn_mimic import return_loaded_model\n",
    "from seaborn import heatmap\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# plot part.\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'VANCOMYCIN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PICKLE LOADS\n",
    "\n",
    "X_TRAIN_MI = pickle.load(open('./pickled_objects/X_TRAIN_MI.txt', 'rb'))\n",
    "X_TRAIN_SEPSIS = pickle.load(open('./pickled_objects/X_TRAIN_SEPSIS.txt', 'rb'))\n",
    "X_TRAIN_VANCOMYCIN = pickle.load(open('./pickled_objects/X_TRAIN_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "Y_TRAIN_MI = pickle.load(open('./pickled_objects/Y_TRAIN_MI.txt', 'rb'))\n",
    "Y_TRAIN_SEPSIS = pickle.load(open('./pickled_objects/Y_TRAIN_SEPSIS.txt', 'rb'))\n",
    "Y_TRAIN_VANCOMYCIN = pickle.load(open('./pickled_objects/Y_TRAIN_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "Y_VAL_MI = pickle.load(open('./pickled_objects/Y_VAL_MI.txt', 'rb'))\n",
    "Y_VAL_SEPSIS = pickle.load(open('./pickled_objects/Y_VAL_SEPSIS.txt', 'rb'))\n",
    "Y_VAL_VANCOMYCIN = pickle.load(open('./pickled_objects/Y_VAL_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "X_VAL_MI = pickle.load(open('./pickled_objects/X_VAL_MI.txt', 'rb'))\n",
    "X_VAL_SEPSIS = pickle.load(open('./pickled_objects/X_VAL_SEPSIS.txt', 'rb'))\n",
    "X_VAL_VANCOMYCIN = pickle.load(open('./pickled_objects/X_VAL_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "Y_TEST_MI = pickle.load(open('./pickled_objects/Y_TEST_MI.txt', 'rb'))\n",
    "Y_TEST_SEPSIS = pickle.load(open('./pickled_objects/Y_TEST_SEPSIS.txt', 'rb'))\n",
    "Y_TEST_VANCOMYCIN = pickle.load(open('./pickled_objects/Y_TEST_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "X_TEST_MI = pickle.load(open('./pickled_objects/X_TEST_MI.txt', 'rb'))\n",
    "X_TEST_SEPSIS = pickle.load(open('./pickled_objects/X_TEST_SEPSIS.txt', 'rb'))\n",
    "X_TEST_VANCOMYCIN = pickle.load(open('./pickled_objects/X_TEST_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "y_boolmat_test_MI = pickle.load(open('./pickled_objects/y_boolmat_test_MI.txt', 'rb'))\n",
    "y_boolmat_test_SEPSIS = pickle.load(open('./pickled_objects/y_boolmat_test_SEPSIS.txt', 'rb'))\n",
    "y_boolmat_test_VANCOMYCIN = pickle.load(open('./pickled_objects/y_boolmat_test_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "x_boolmat_test_MI = pickle.load(open('./pickled_objects/x_boolmat_test_MI.txt', 'rb'))\n",
    "x_boolmat_test_SEPSIS = pickle.load(open('./pickled_objects/x_boolmat_test_SEPSIS.txt', 'rb'))\n",
    "x_boolmat_test_VANCOMYCIN = pickle.load(open('./pickled_objects/x_boolmat_test_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "no_features_cols_MI = pickle.load(open('./pickled_objects/no_feature_cols_MI.txt', 'rb'))\n",
    "no_features_cols_SEPSIS = pickle.load(open('./pickled_objects/no_feature_cols_SEPSIS.txt', 'rb'))\n",
    "no_features_cols_VANCOMYCIN = pickle.load(open('./pickled_objects/no_feature_cols_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "features_MI = pickle.load(open('./pickled_objects/features_MI.txt', 'rb'))\n",
    "features_SEPSIS = pickle.load(open('./pickled_objects/features_SEPSIS.txt', 'rb'))\n",
    "features_VANCOMYCIN = pickle.load(open('./pickled_objects/features_VANCOMYCIN.txt', 'rb'))\n",
    "\n",
    "if target == 'MI':\n",
    "    my_cmap = ListedColormap(sns.color_palette(\"Reds\", 150))\n",
    "    color_list = sns.color_palette(\"Reds\", 14)\n",
    "    color_list_reduced = sns.color_palette(\"Reds\", 7)\n",
    "    X_TRAIN = X_TRAIN_MI\n",
    "    X_VAL = X_VAL_MI\n",
    "    Y_TRAIN = Y_TRAIN_MI\n",
    "    Y_VAL = Y_VAL_MI\n",
    "    Y_TEST = Y_TEST_MI\n",
    "    X_TEST = X_TEST_MI\n",
    "    y_boolmat_test = y_boolmat_test_MI\n",
    "    x_boolmat_test = x_boolmat_test_MI\n",
    "    features = features_MI\n",
    "    \n",
    "elif target == 'SEPSIS':\n",
    "    my_cmap = sns.cubehelix_palette(14, start=2, rot=0, dark=0.25, light=.95, as_cmap=True)\n",
    "    color_list = sns.cubehelix_palette(14, start=2, rot=0, dark=0.15, light=.8)\n",
    "    color_list_reduced = sns.cubehelix_palette(7, start=2, rot=0, dark=0.15, light=.8)\n",
    "    X_TRAIN = X_TRAIN_SEPSIS\n",
    "    X_VAL = X_VAL_SEPSIS\n",
    "    Y_TRAIN = Y_TRAIN_SEPSIS\n",
    "    Y_VAL = Y_VAL_SEPSIS\n",
    "    Y_TEST = Y_TEST_SEPSIS\n",
    "    X_TEST = X_TEST_SEPSIS\n",
    "    y_boolmat_test = y_boolmat_test_SEPSIS\n",
    "    x_boolmat_test = x_boolmat_test_SEPSIS\n",
    "    features = features_SEPSIS\n",
    "    \n",
    "elif target == 'VANCOMYCIN':\n",
    "    my_cmap= sns.cubehelix_palette(14, as_cmap=True)\n",
    "    color_list = sns.cubehelix_palette(14)\n",
    "    color_list_reduced = sns.cubehelix_palette(7)\n",
    "    X_TRAIN = X_TRAIN_VANCOMYCIN\n",
    "    X_VAL = X_VAL_VANCOMYCIN\n",
    "    Y_TRAIN = Y_TRAIN_VANCOMYCIN\n",
    "    Y_VAL = Y_VAL_VANCOMYCIN\n",
    "    Y_TEST = Y_TEST_VANCOMYCIN\n",
    "    X_TEST = X_TEST_VANCOMYCIN\n",
    "    y_boolmat_test = y_boolmat_test_VANCOMYCIN\n",
    "    x_boolmat_test = x_boolmat_test_VANCOMYCIN\n",
    "    features = features_VANCOMYCIN\n",
    "    \n",
    "# Y_TRAIN[Y_TRAIN == -1] = np.nan\n",
    "# Y_VAL[Y_VAL == -1] = np.nan\n",
    "# Y_TEST[Y_TEST == -1] = np.nan\n",
    "Y_TOTAL = np.concatenate([Y_TRAIN, Y_VAL, Y_TEST], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_MI = np.concatenate([Y_TRAIN_MI, Y_VAL_MI], axis=0)\n",
    "Y_SEPSIS = np.concatenate([Y_TRAIN_SEPSIS, Y_VAL_SEPSIS], axis=0)\n",
    "Y_VANCOMYCIN = np.concatenate([Y_TRAIN_VANCOMYCIN, Y_VAL_VANCOMYCIN], axis=0)\n",
    "\n",
    "print(np.sum(np.sum(Y_MI.squeeze(), axis=1) > 0))\n",
    "print(np.sum(np.sum(Y_SEPSIS.squeeze(), axis=1) > 0))\n",
    "print(np.sum(np.sum(Y_VANCOMYCIN.squeeze(), axis=1) > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(no_features_cols_MI)\n",
    "print(no_features_cols_SEPSIS)\n",
    "print(no_features_cols_VANCOMYCIN)\n",
    "\n",
    "print(X_TRAIN_MI.shape)\n",
    "print(X_TRAIN_SEPSIS.shape)\n",
    "print(X_TRAIN_VANCOMYCIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = X_VAL.shape[1] #number of time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target == 'MI':\n",
    "    m = return_loaded_model(model_name=\"kaji_mach_final_no_mask_MI_pad14\")#_attention\")\n",
    "    m_80 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_MI_pad14_80_percent\")\n",
    "    m_60 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_MI_pad14_60_percent\")\n",
    "    m_40 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_MI_pad14_40_percent\")\n",
    "    m_20 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_MI_pad14_20_percent\")\n",
    "    m_10 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_MI_pad14_10_percent\")\n",
    "    m_5 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_MI_pad14_5_percent\")\n",
    "    #m_bench = return_loaded_model(model_name=\"kaji_mach_final_no_mask_MI_pad14_bench\")\n",
    "elif target == 'SEPSIS':\n",
    "    m = return_loaded_model(model_name=\"kaji_mach_final_no_mask_SEPSIS_pad14\")#_attention\")\n",
    "    m_80 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_SEPSIS_pad14_80_percent\")\n",
    "    m_60 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_SEPSIS_pad14_60_percent\")\n",
    "    m_40 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_SEPSIS_pad14_40_percent\")\n",
    "    m_20 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_SEPSIS_pad14_20_percent\")\n",
    "    m_10 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_SEPSIS_pad14_10_percent\")\n",
    "    m_5 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_SEPSIS_pad14_5_percent\")\n",
    "    #m_bench = return_loaded_model(model_name=\"kaji_mach_final_no_mask_SEPSIS_pad14_bench\")\n",
    "elif target == 'VANCOMYCIN':\n",
    "    m = return_loaded_model(model_name=\"kaji_mach_final_no_mask_VANCOMYCIN_pad14\")#_attention\")\n",
    "    m_80 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_VANCOMYCIN_pad14_80_percent\")\n",
    "    m_60 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_VANCOMYCIN_pad14_60_percent\")\n",
    "    m_40 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_VANCOMYCIN_pad14_40_percent\")\n",
    "    m_20 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_VANCOMYCIN_pad14_20_percent\")\n",
    "    m_10 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_VANCOMYCIN_pad14_10_percent\")\n",
    "    m_5 = return_loaded_model(model_name=\"kaji_mach_final_no_mask_VANCOMYCIN_pad14_5_percent\")\n",
    "   #m_bench = return_loaded_model(model_name=\"kaji_mach_final_no_mask_VANCOMYCIN_pad14_bench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## SUPPLEMENTARY FIGURE 1 ##\n",
    "############################\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "    \n",
    "## TOTAL\n",
    "\n",
    "### When do people have incidents?\n",
    "\n",
    "# number of people who are positive on a given day\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.title('Number of total patients positive on a given day')\n",
    "plt.ylabel('Number of total patients with/on {0}'.format(target))\n",
    "plt.xlabel('Day')\n",
    "y_vector_total = np.nansum(Y_TOTAL, axis=0).squeeze()\n",
    "print(\"The total kurtosis is {0} with {1} % of events \\\n",
    "occuring between days 0 and 2\".format(kurtosis(y_vector_total), \n",
    "                                            100*int(np.sum(y_vector_total[0:2]))/np.sum(y_vector_total)))\n",
    "color_rank = np.argsort(np.argsort(y_vector_total))\n",
    "sns.barplot(y=y_vector_total, x=np.arange(14), palette=np.array(color_list)[color_rank])\n",
    "\n",
    "plt.savefig('./figures/{0}_Total_Patients_Positive_Supplemental_Figure_1.eps'.format(target), format='eps',\n",
    "             dpi=300, bbox_inches='tight')\n",
    "\n",
    "# first incident - number of people who had their first incident on a given day\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.title('Number of total patients whose incidence began on a given day')\n",
    "plt.ylabel('Number of total patients with/on {0}'.format(target))\n",
    "plt.xlabel('Day')\n",
    "POS_Y_TOTAL = Y_TOTAL[np.nansum(Y_TOTAL.squeeze(), axis=1) == 1]\n",
    "(days_total, value_counts_total) = np.unique(np.nanargmax(POS_Y_TOTAL, axis=1), return_counts=True)\n",
    "day_value_dict_total = dict(zip(np.arange(14), np.zeros(14)))\n",
    "for i in range(len(days_total)):\n",
    "    day_value_dict_total[days_total[i]] = value_counts_total[i]\n",
    "y_vector_total_pos = list(day_value_dict_total.values())\n",
    "color_rank = np.argsort(np.argsort(y_vector_total_pos))\n",
    "sns.barplot(y=y_vector_total_pos, x=np.arange(14), palette=np.array(color_list)[color_rank])\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig('./figures/{0}_Total_Patients_First_Positive_Supplemental_Figure_1.eps'.format(target), \n",
    "            format='eps', dpi=300, bbox_inches='tight')\n",
    "\n",
    "## TRAIN\n",
    "\n",
    "## When do people have incidents?\n",
    "\n",
    "# number of people who are positive on a given day\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.title('Number of train patients positive on a given day')\n",
    "plt.ylabel('Number of train patients with/on {0}'.format(target))\n",
    "plt.xlabel('Day')\n",
    "y_vector_train = np.nansum(Y_TRAIN, axis=0).squeeze()\n",
    "print(\"The train kurtosis is {0} with {1} % of events \\\n",
    "occuring between days 0 and 2\".format(kurtosis(y_vector_train), \n",
    "                                            100*int(np.sum(y_vector_train[0:2]))/np.sum(y_vector_train)))\n",
    "color_rank = np.argsort(np.argsort(y_vector_train))\n",
    "sns.barplot(y=y_vector_train, x=np.arange(14), palette=np.array(color_list)[color_rank])\n",
    "\n",
    "plt.savefig('./figures/{0}_Train_Patients_Positive_Supplemental_Figure_1.eps'.format(target), format='eps',\n",
    "             dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# first incident - number of people who had their first incident on a given day\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.title('Number of train patients whose incidence began on a given day')\n",
    "plt.ylabel('Number of train patients with/on {0}'.format(target))\n",
    "plt.xlabel('Day')\n",
    "POS_Y_TRAIN = Y_TRAIN[np.nansum(Y_TRAIN.squeeze(), axis=1) == 1]\n",
    "(days_train_pos, value_counts_train_pos) = np.unique(np.nanargmax(POS_Y_TRAIN, axis=1), return_counts=True)\n",
    "day_value_dict_train_pos = dict(zip(np.arange(14), np.zeros(14)))\n",
    "for i in range(len(days_train_pos)):\n",
    "    day_value_dict_train_pos[days_train_pos[i]] = value_counts_train_pos[i]\n",
    "y_vector_train_pos = list(day_value_dict_train_pos.values())\n",
    "color_rank = np.argsort(np.argsort(y_vector_train_pos))\n",
    "sns.barplot(y=y_vector_train_pos, x=np.arange(14), palette=np.array(color_list)[color_rank])\n",
    "\n",
    "plt.savefig('./figures/{0}_Train_Patients_First_Positive_Supplemental_Figure_1.eps'.format(target), \n",
    "            format='eps', dpi=300, bbox_inches='tight')\n",
    "\n",
    "## TEST\n",
    "\n",
    "# number of people who are positive on a given day\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.title('Number of test patients positive on a given day')\n",
    "plt.ylabel('Number of test patients with/on {0}'.format(target))\n",
    "plt.xlabel('Day')\n",
    "y_vector_test = np.nansum(Y_TEST, axis=0).squeeze()\n",
    "print(\"The test kurtosis is {0} with {1} % of events \\\n",
    "occuring between days 0 and 2\".format(kurtosis(y_vector_test), \n",
    "                                          100*int(np.sum(y_vector_test[0:2]))/np.sum(y_vector_test)))\n",
    "color_rank = np.argsort(np.argsort(y_vector_test))\n",
    "sns.barplot(y=y_vector_test, x=np.arange(14), palette=np.array(color_list)[color_rank])\n",
    "\n",
    "plt.savefig('./figures/{0}_Test_Patients_Positive_Supplemental_Figure_1.eps'.format(target), \n",
    "            format='eps', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# first incident - nmber of people who had their first incident on a given day\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.title('Number of test patients whose incidence began on a given day')\n",
    "plt.ylabel('Number of test patients with/on {0}'.format(target))\n",
    "plt.xlabel('Day')\n",
    "POS_Y_TEST = Y_TEST[np.nansum(Y_TEST.squeeze(), axis=1) == 1]\n",
    "(days, value_counts) = np.unique(np.nanargmax(POS_Y_TEST, axis=1), return_counts=True)\n",
    "day_value_dict = dict(zip(np.arange(14), np.zeros(14)))\n",
    "for i in range(len(days)):\n",
    "    day_value_dict[days[i]] = value_counts[i]\n",
    "y_vector_test_pos = list(day_value_dict.values())\n",
    "color_rank = np.argsort(np.argsort(y_vector_test_pos))\n",
    "sns.barplot(y=y_vector_test_pos, x=np.arange(14), palette=np.array(color_list)[color_rank])\n",
    "\n",
    "plt.savefig('./figures/{0}_Test_Patients_First_Positive_Supplemental_Figure_1.eps'.format(target), \n",
    "            format='eps', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## SUPPLEMENTARY FIGURE 2 ###\n",
    "#############################\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "Y_PRED_mask_0 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "Y_PRED_80_percent = m_80.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "Y_PRED_60_percent = m_60.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "Y_PRED_40_percent = m_40.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "Y_PRED_20_percent = m_20.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "Y_PRED_10_percent = m_10.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "Y_PRED_5_percent = m_5.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "# AUROC values with models that have been trained with various fractions of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## SUPPLEMENTARY FIGURE 2 ###\n",
    "#############################\n",
    "\n",
    "(fpr_100, tpr_100, thresholds_100) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_0[~y_boolmat_test])\n",
    "(fpr_80, tpr_80, thresholds_80) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_80_percent[~y_boolmat_test])\n",
    "(fpr_60, tpr_60, thresholds_60) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_60_percent[~y_boolmat_test])\n",
    "(fpr_40, tpr_40, thresholds_40) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_40_percent[~y_boolmat_test])\n",
    "(fpr_20, tpr_20, thresholds_20) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_20_percent[~y_boolmat_test])\n",
    "(fpr_10, tpr_10, thresholds_10) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_10_percent[~y_boolmat_test])\n",
    "(fpr_5, tpr_5, thresholds_5) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_5_percent[~y_boolmat_test])\n",
    "\n",
    "fpr_tprs = [(fpr_100, tpr_100), (fpr_80, tpr_80), (fpr_60, tpr_60),        \n",
    "            (fpr_40, tpr_40), (fpr_20, tpr_20), (fpr_10, tpr_10), (fpr_5, tpr_5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## SUPPLEMENTARY FIGURE 2 ###\n",
    "#############################\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "for color, fpr_tpr_tuple, i in zip(np.array(color_list_reduced)[::-1], fpr_tprs, [100,80,60,40,20,10,5]):\n",
    "    plt.plot(fpr_tpr_tuple[0], fpr_tpr_tuple[1], label='{0}% of Training Data'.format(i), color=color)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.axhline(0, color='black')\n",
    "plt.axvline(0, color='black')\n",
    "legend = plt.legend(loc=\"lower right\", prop={'size': 10}, bbox_to_anchor=(1.48, 0.05))\n",
    "plt.savefig('./figures/{0}_less_data_roc_curves_Supplemental_Figure_2.eps'.format(target), format='eps',\n",
    "             dpi=300, facecolor='white', transparent=True, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "\n",
    "# 100 % Training Data\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_0[~y_boolmat_test]))\n",
    "# 80 % Training Data\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_80_percent[~y_boolmat_test]))\n",
    "# 60 % Training Data\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_60_percent[~y_boolmat_test]))\n",
    "# 40 % Training Data\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_40_percent[~y_boolmat_test]))\n",
    "# 20 % Training Data\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_20_percent[~y_boolmat_test]))\n",
    "# 10 % Training Data\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_10_percent[~y_boolmat_test]))\n",
    "# 5 % Training Data\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_5_percent[~y_boolmat_test]))\n",
    "\n",
    "## 100% Training Data ##\n",
    "TN, FP, FN, TP = confusion_matrix(Y_TEST[~y_boolmat_test], np.around(Y_PRED_mask_0[~y_boolmat_test])).ravel()\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"PPV for full model is {0}\".format(PPV))\n",
    "CR = classification_report(Y_TEST[~y_boolmat_test], np.around(Y_PRED_mask_0[~y_boolmat_test]))\n",
    "\n",
    "print(\"Sensitivity for full model is {0}\".format(CR.split('\\n')[3].split()[2]))\n",
    "# classification_report(Y_TEST[~y_boolmat_test], np.around(Y_PRED_mask_0[~y_boolmat_test]))\n",
    "\n",
    "print(classification_report(Y_TEST[~y_boolmat_test], np.around(Y_PRED_mask_0[~y_boolmat_test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' this function is adapted from Keras documentation '''\n",
    "from tensorflow.python.keras.backend import eager_learning_phase_scope\n",
    "def get_activations(model, inputs, print_shape_only=False, layer_name=None, verbose=False):\n",
    "  \n",
    "    \"\"\"\n",
    "    Get activations from a model\n",
    "    Args:\n",
    "        model: a keras model\n",
    "        inputs: the inputs for the model\n",
    "        print_shape_only: whether to print the shape of the layer or the whole activation layer\n",
    "        layer_name: name of specific layer to return\n",
    "        verbose: whether to show all outputs\n",
    "    Returns:\n",
    "        activations: list, list of activations\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name == layer_name]  # all layer outputs\n",
    "        \n",
    "    #https://github.com/tensorflow/tensorflow/issues/34201\n",
    "    funcs = [K.function([inp], [out]) for out in outputs]  # evaluation functions\n",
    "    with eager_learning_phase_scope(value=1): # 0=test, 1=train\n",
    "        layer_outputs = [func([inputs, 1.])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        if verbose:\n",
    "            print('----- activations -----')\n",
    "            if print_shape_only:\n",
    "                print(layer_activations.shape)\n",
    "            else:\n",
    "                print(layer_activations)\n",
    "    return activations\n",
    "\n",
    "def normalize_activations(activations_matrix):\n",
    "    means = np.nanmean(activations_matrix, axis=0)\n",
    "    stds = np.nanstd(activations_matrix, axis=0)\n",
    "    return (activations_matrix - means) / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ACTIVATIONS MATRIX ; OUTPUT IS (BATCH_SIZE, TIME_STEPS, FEATURES)\n",
    "\n",
    "activations = get_activations(m, X_TEST, print_shape_only=True, layer_name='attention_vec')[0]\n",
    "activations[x_boolmat_test] = np.nan\n",
    "\n",
    "# AVERAGE THE ATTENTION MATRIX OVER FEATURES ; OUTPUT IS BATCH_SIZE, TIME_STEPS\n",
    "attention_matrix = np.nanmean(activations, axis=2).squeeze()\n",
    "\n",
    "# AVERAGE ATTENTION VECTOR ACROSS SAMPLES ; OUTPUT IS 1D TIME_STEPS\n",
    "attention_vector_final = np.nanmean(attention_matrix, axis=0)\n",
    "\n",
    "# This allows us to rank color intensity by activation. We sort the intensities, then argsort the indices ##\n",
    "color_order = np.argsort(attention_vector_final, axis=0)\n",
    "color_order_order = np.argsort(color_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_vector_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Due to the way features are selectd from the EMR and the fact potassium can be a \n",
    "delivered medication or a lab value, special care was taken to ensure proper representation on heatmaps '''\n",
    "\n",
    "if 'digoxin(?!.*fab)' in features:\n",
    "    indexy = features.index('digoxin(?!.*fab)')\n",
    "    features[indexy] = 'digoxin'\n",
    "    \n",
    "if 'potassium_y' in features:\n",
    "    indexy = features.index('potassium_y')\n",
    "    features[indexy] = 'potassium_med'\n",
    "    \n",
    "if 'potassium_x' in features:\n",
    "    indexy = features.index('potassium_x')\n",
    "    features[indexy] = 'potassium'\n",
    "    \n",
    "if 'cipfloxacin' in features:\n",
    "    indexy = features.index('cipfloxacin')\n",
    "    features[indexy] = 'ciprofloxacin'\n",
    "\n",
    "features = [feature.lower() for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURES BY CATEGORY ##\n",
    "\n",
    "cbc_diff_features = ['RBCs', 'WBCs', 'platelets', 'hemoglobin', 'hemocrit', \n",
    "                              'atypical lymphocytes', 'bands', 'basophils', 'eosinophils', 'neutrophils',\n",
    "                              'lymphocytes', 'monocytes', 'polymorphonuclear leukocytes']\n",
    "                      \n",
    "vital_features = ['temperature (F)', 'heart rate', 'respiratory rate', 'systolic', 'diastolic',\n",
    "                  'pulse oximetry']\n",
    "\n",
    "lab_features = ['troponin', 'HDL', 'LDL', 'BUN', 'INR', 'PTT', 'PT', 'triglycerides', 'creatinine',\n",
    "                  'glucose', 'sodium', 'potassium', 'chloride', 'bicarbonate',\n",
    "                  'blood culture', 'urine culture', 'surface culture', 'sputum' + \n",
    "                  ' culture', 'wound culture', 'Inspired O2 Fraction', 'central venous pressure', \n",
    "                  'PEEP Set', 'tidal volume', 'anion gap']\n",
    "                  \n",
    "demographic_features = ['age', 'm', 'black', 'daily weight', 'tobacco', 'diabetes', 'history of CV events']\n",
    "\n",
    "med_features = ['epoetin', 'warfarin', 'heparin', 'enoxaparin', 'fondaparinux',\n",
    "                                      'asprin', 'ketorolac', 'acetominophen', \n",
    "                                      'insulin', 'glucagon', \n",
    "                                      'potassium_med', 'calcium gluconate', \n",
    "                                      'fentanyl', 'magensium sulfate', \n",
    "                                      'D5W', 'dextrose', \n",
    "                                      'ranitidine', 'ondansetron', 'pantoprazole', 'metoclopramide', \n",
    "                                      'lisinopril', 'captopril', 'statin',  \n",
    "                                      'hydralazine', 'diltiazem', \n",
    "                                      'carvedilol', 'metoprolol', 'labetalol', 'atenolol',\n",
    "                                      'amiodarone', 'digoxin',\n",
    "                                      'clopidogrel', 'nitroprusside', 'nitroglycerin',\n",
    "                                      'vasopressin', 'hydrochlorothiazide', 'furosemide', \n",
    "                                      'atropine', 'neostigmine',\n",
    "                                      'levothyroxine',\n",
    "                                      'oxycodone', 'hydromorphone', 'fentanyl citrate', \n",
    "                                      'tacrolimus', 'prednisone', \n",
    "                                      'phenylephrine', 'norepinephrine',\n",
    "                                      'haloperidol', 'phenytoin', 'trazodone', 'levetiracetam',\n",
    "                                      'diazepam', 'clonazepam',\n",
    "                                      'propofol', 'zolpidem', 'midazolam', \n",
    "                                      'albuterol', 'ipratropium', \n",
    "                                      'diphenhydramine',  \n",
    "                                      '0.9% Sodium Chloride',\n",
    "                                      'phytonadione', \n",
    "                                      'metronidazole', \n",
    "                                      'cefazolin', 'cefepime', 'vancomycin', 'levofloxacin',\n",
    "                                      'ciprofloxacin', 'fluconazole', \n",
    "                                      'meropenem', 'ceftriaxone', 'piperacillin',\n",
    "                                      'ampicillin-sulbactam', 'nafcillin', 'oxacillin',\n",
    "                                      'amoxicillin', 'penicillin', 'SMX-TMP']\n",
    "\n",
    "cbc_diff_features = [[i.lower(), i.lower()+'_min', i.lower()+'_max', i.lower()+'_std'] for i in cbc_diff_features]\n",
    "vital_features = [[i.lower(), i.lower()+'_min', i.lower()+'_max', i.lower()+'_std'] for i in vital_features]\n",
    "lab_features = [[i.lower(), i.lower()+'_min', i.lower()+'_max', i.lower()+'_std'] for i in lab_features]\n",
    "demographic_features = [i.lower() for i in demographic_features]\n",
    "med_features = [i.lower() for i in med_features]\n",
    "\n",
    "cbc_diff_feature_array = np.array(cbc_diff_features).flatten()\n",
    "vital_features_array = np.array(vital_features).flatten()\n",
    "lab_features_array = np.array(lab_features).flatten()\n",
    "demographic_feature_array = np.array(demographic_features).flatten()\n",
    "med_features_array = np.array(med_features).flatten()\n",
    "\n",
    "features_built = np.hstack([cbc_diff_feature_array,vital_features_array,\n",
    "                            lab_features_array,demographic_feature_array,med_features_array])\n",
    "\n",
    "features_built_reduced = [i for i in features_built if i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identifies the index in the features list in the desired order ##\n",
    "arranged_indices = [features.index(i) for i in features_built_reduced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a sanity check to ensure that features_built_reduced has the same number of elements as our target ##\n",
    "\n",
    "print(len(features_SEPSIS))\n",
    "print(len(features_MI))\n",
    "print(len(features_VANCOMYCIN))\n",
    "print('\\n')\n",
    "print(len(features_built))\n",
    "print(len(features_built_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "## FIGURE 1 ##\n",
    "##############\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "Y_PRED_mask_0 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 1\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_1 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 2\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_2 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 3\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_3 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 4\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_4 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 5\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_5 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 6\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_6 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 7\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_7 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 8\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_8 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 9\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_9 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 10\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_10 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 11\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_11 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 12\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_12 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK\n",
    "\n",
    "X_TEST_MASK = np.copy(X_TEST)\n",
    "mask = 13\n",
    "X_TEST_MASK[x_boolmat_test] = 0\n",
    "X_TEST_MASK[:,mask:,:] = 0\n",
    "Y_PRED_mask_13 = m.predict(X_TEST_MASK)\n",
    "del X_TEST_MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "## FIGURE 1 ##\n",
    "##############\n",
    "\n",
    "(fpr_mask_0, tpr_mask_0, thresholds_mask_0) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_0[~y_boolmat_test])\n",
    "(fpr_mask_1, tpr_mask_1, thresholds_mask_1) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_1[~y_boolmat_test])\n",
    "(fpr_mask_2, tpr_mask_2, thresholds_mask_2) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_2[~y_boolmat_test])\n",
    "(fpr_mask_3, tpr_mask_3, thresholds_mask_3) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_3[~y_boolmat_test])\n",
    "(fpr_mask_4, tpr_mask_4, thresholds_mask_4) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_4[~y_boolmat_test])\n",
    "(fpr_mask_5, tpr_mask_5, thresholds_mask_5) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_5[~y_boolmat_test])\n",
    "(fpr_mask_6, tpr_mask_6, thresholds_mask_6) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_6[~y_boolmat_test])\n",
    "(fpr_mask_7, tpr_mask_7, thresholds_mask_7) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_7[~y_boolmat_test])\n",
    "(fpr_mask_8, tpr_mask_8, thresholds_mask_8) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_8[~y_boolmat_test])\n",
    "(fpr_mask_9, tpr_mask_9, thresholds_mask_9) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_9[~y_boolmat_test])\n",
    "(fpr_mask_10, tpr_mask_10, thresholds_mask_10) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_10[~y_boolmat_test])\n",
    "(fpr_mask_11, tpr_mask_11, thresholds_mask_11) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_11[~y_boolmat_test])\n",
    "(fpr_mask_12, tpr_mask_12, thresholds_mask_12) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_12[~y_boolmat_test])\n",
    "(fpr_mask_13, tpr_mask_13, thresholds_mask_13) = roc_curve(Y_TEST[~y_boolmat_test], Y_PRED_mask_13[~y_boolmat_test])\n",
    "\n",
    "fpr_tprs = [(fpr_mask_1, tpr_mask_1), (fpr_mask_2, tpr_mask_2), (fpr_mask_3, tpr_mask_3), (fpr_mask_4, tpr_mask_4),\n",
    "            (fpr_mask_5, tpr_mask_5), (fpr_mask_6, tpr_mask_6), (fpr_mask_7, tpr_mask_7), (fpr_mask_8, tpr_mask_8),\n",
    "            (fpr_mask_9, tpr_mask_9), (fpr_mask_10, tpr_mask_10), (fpr_mask_11, tpr_mask_11), (fpr_mask_12, tpr_mask_12), \n",
    "            (fpr_mask_13, tpr_mask_13), (fpr_mask_0, tpr_mask_0)]\n",
    "\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_0[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_13[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_12[~y_boolmat_test]))   \n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_11[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_10[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_9[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_8[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_7[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_6[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_5[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_4[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_3[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_2[~y_boolmat_test]))\n",
    "print(roc_auc_score(Y_TEST[~y_boolmat_test], Y_PRED_mask_1[~y_boolmat_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "## FIGURE 1 ##\n",
    "##############\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for color, fpr_tpr_tuple in zip(color_list, fpr_tprs):\n",
    "    if counter != 14:\n",
    "        plt.plot(fpr_tpr_tuple[0], fpr_tpr_tuple[1], label='Mask Post Day {0}'.format(counter), color=color)\n",
    "        counter = counter+1\n",
    "    elif counter == 14:\n",
    "        plt.plot(fpr_tpr_tuple[0], fpr_tpr_tuple[1], label='No Mask', color=color)\n",
    "        \n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.axhline(0, color='black')\n",
    "plt.axvline(0, color='black')\n",
    "legend = plt.legend(loc=\"lower right\", prop={'size': 10}, bbox_to_anchor=(1.41, 0))\n",
    "plt.savefig('./figures/{0}_roc_curves_Fig_1.eps'.format(target), format='eps',\n",
    "             dpi=300, facecolor='white', transparent=True, bbox_extra_artists=(legend,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## FIGURE 2 LAG EXPERIMENTS ##\n",
    "##############################\n",
    "\n",
    "### 1 DAY LAGGED EXPERIMENTS ###\n",
    "\n",
    "### Y_PRED_mask_0_LAG_1 ###\n",
    "\n",
    "Y_PRED_mask_0_LAG_1 = np.concatenate([Y_PRED_mask_0[:,i][~y_boolmat_test[:,i,:]] for i in range(1,13)], axis=0)\n",
    "Y_PRED_mask_0_LAG_2 = np.concatenate([Y_PRED_mask_0[:,i][~y_boolmat_test[:,i,:]] for i in range(2,13)], axis=0)\n",
    "Y_PRED_mask_0_LAG_3 = np.concatenate([Y_PRED_mask_0[:,i][~y_boolmat_test[:,i,:]] for i in range(3,13)], axis=0)\n",
    "Y_PRED_mask_0_LAG_4 = np.concatenate([Y_PRED_mask_0[:,i][~y_boolmat_test[:,i,:]] for i in range(4,13)], axis=0)\n",
    "Y_PRED_mask_0_LAG_5 = np.concatenate([Y_PRED_mask_0[:,i][~y_boolmat_test[:,i,:]] for i in range(5,13)], axis=0)\n",
    "Y_PRED_mask_0_LAG_6 = np.concatenate([Y_PRED_mask_0[:,i][~y_boolmat_test[:,i,:]] for i in range(6,13)], axis=0)\n",
    "Y_PRED_mask_0_LAG_7 = np.concatenate([Y_PRED_mask_0[:,i][~y_boolmat_test[:,i,:]] for i in range(7,13)], axis=0)\n",
    "\n",
    "# below is an equivalent representation \n",
    "\n",
    "# Y_PRED_mask_0_LAG_1 = np.concatenate([Y_PRED_mask_0[:,1][~y_boolmat_test[:,1,::]], \n",
    "#                                     Y_PRED_mask_0[:,2][~y_boolmat_test[:,2,::]],\n",
    "#                                     Y_PRED_mask_0[:,3][~y_boolmat_test[:,3,::]], \n",
    "#                                     Y_PRED_mask_0[:,4][~y_boolmat_test[:,4,::]], \n",
    "#                                     Y_PRED_mask_0[:,5][~y_boolmat_test[:,5,::]], \n",
    "#                                     Y_PRED_mask_0[:,6][~y_boolmat_test[:,6,::]], \n",
    "#                                     Y_PRED_mask_0[:,7][~y_boolmat_test[:,7,::]], \n",
    "#                                     Y_PRED_mask_0[:,8][~y_boolmat_test[:,8,::]],\n",
    "#                                     Y_PRED_mask_0[:,9][~y_boolmat_test[:,9,::]], \n",
    "#                                     Y_PRED_mask_0[:,10][~y_boolmat_test[:,10,::]], \n",
    "#                                     Y_PRED_mask_0[:,11][~y_boolmat_test[:,11,::]], \n",
    "#                                     Y_PRED_mask_0[:,12][~y_boolmat_test[:,12,::]],\n",
    "#                                     Y_PRED_mask_0[:,13][~y_boolmat_test[:,13,::]]], axis=0)\n",
    "                                      \n",
    "### all the first day soft every person, all the second days, third days, in a 1D vector\n",
    "                                      \n",
    "Y_TEST_LAG_1 = np.concatenate([Y_TEST[:,i][~y_boolmat_test[:,i,::]] for i in range(1,14)], axis=0)\n",
    "Y_TEST_LAG_2 = np.concatenate([Y_TEST[:,i][~y_boolmat_test[:,i,::]] for i in range(2,14)], axis=0)\n",
    "Y_TEST_LAG_3 = np.concatenate([Y_TEST[:,i][~y_boolmat_test[:,i,::]] for i in range(3,14)], axis=0)\n",
    "Y_TEST_LAG_4 = np.concatenate([Y_TEST[:,i][~y_boolmat_test[:,i,::]] for i in range(4,14)], axis=0)\n",
    "Y_TEST_LAG_5 = np.concatenate([Y_TEST[:,i][~y_boolmat_test[:,i,::]] for i in range(5,14)], axis=0)\n",
    "Y_TEST_LAG_6 = np.concatenate([Y_TEST[:,i][~y_boolmat_test[:,i,::]] for i in range(6,14)], axis=0)\n",
    "Y_TEST_LAG_7 = np.concatenate([Y_TEST[:,i][~y_boolmat_test[:,i,::]] for i in range(7,14)], axis=0)\n",
    "\n",
    "#############\n",
    "## Y_PREDS ##\n",
    "#############                                     \n",
    "                                      \n",
    "Y_PRED_LAG_1 = np.concatenate([Y_PRED_mask_1[:,1,::][~y_boolmat_test[:,1,::]], \n",
    "                             Y_PRED_mask_2[:,2,::][~y_boolmat_test[:,2,::]], \n",
    "                             Y_PRED_mask_3[:,3,::][~y_boolmat_test[:,3,::]], \n",
    "                             Y_PRED_mask_4[:,4,::][~y_boolmat_test[:,4,:]],\n",
    "                             Y_PRED_mask_5[:,5,::][~y_boolmat_test[:,5,::]], \n",
    "                             Y_PRED_mask_6[:,6,::][~y_boolmat_test[:,6,::]], \n",
    "                             Y_PRED_mask_7[:,7,::][~y_boolmat_test[:,7,::]], \n",
    "                             Y_PRED_mask_8[:,8,::][~y_boolmat_test[:,8,::]],\n",
    "                             Y_PRED_mask_9[:,9,::][~y_boolmat_test[:,9,::]], \n",
    "                             Y_PRED_mask_10[:,10,::][~y_boolmat_test[:,10,::]], \n",
    "                             Y_PRED_mask_11[:,11,::][~y_boolmat_test[:,11,::]], \n",
    "                             Y_PRED_mask_12[:,12,::][~y_boolmat_test[:,12,::]],\n",
    "                             Y_PRED_mask_13[:,13,::][~y_boolmat_test[:,13,::]]], axis=0)\n",
    "\n",
    "Y_PRED_LAG_2 = np.concatenate([Y_PRED_mask_1[:,2,::][~y_boolmat_test[:,2,::]], \n",
    "                             Y_PRED_mask_2[:,3,::][~y_boolmat_test[:,3,::]], \n",
    "                             Y_PRED_mask_3[:,4,::][~y_boolmat_test[:,4,::]], \n",
    "                             Y_PRED_mask_4[:,5,::][~y_boolmat_test[:,5,:]],\n",
    "                             Y_PRED_mask_5[:,6,::][~y_boolmat_test[:,6,::]], \n",
    "                             Y_PRED_mask_6[:,7,::][~y_boolmat_test[:,7,::]], \n",
    "                             Y_PRED_mask_7[:,8,::][~y_boolmat_test[:,8,::]], \n",
    "                             Y_PRED_mask_8[:,9,::][~y_boolmat_test[:,9,::]],\n",
    "                             Y_PRED_mask_9[:,10,::][~y_boolmat_test[:,10,::]], \n",
    "                             Y_PRED_mask_10[:,11,::][~y_boolmat_test[:,11,::]], \n",
    "                             Y_PRED_mask_11[:,12,::][~y_boolmat_test[:,12,::]], \n",
    "                             Y_PRED_mask_12[:,13,::][~y_boolmat_test[:,13,::]]], axis=0)\n",
    "\n",
    "Y_PRED_LAG_3 = np.concatenate([Y_PRED_mask_1[:,3,::][~y_boolmat_test[:,3,::]], \n",
    "                             Y_PRED_mask_2[:,4,::][~y_boolmat_test[:,4,::]], \n",
    "                             Y_PRED_mask_3[:,5,::][~y_boolmat_test[:,5,::]], \n",
    "                             Y_PRED_mask_4[:,6,::][~y_boolmat_test[:,6,:]],\n",
    "                             Y_PRED_mask_5[:,7,::][~y_boolmat_test[:,7,::]], \n",
    "                             Y_PRED_mask_6[:,8,::][~y_boolmat_test[:,8,::]], \n",
    "                             Y_PRED_mask_7[:,9,::][~y_boolmat_test[:,9,::]], \n",
    "                             Y_PRED_mask_8[:,10,::][~y_boolmat_test[:,10,::]],\n",
    "                             Y_PRED_mask_9[:,11,::][~y_boolmat_test[:,11,::]], \n",
    "                             Y_PRED_mask_10[:,12,::][~y_boolmat_test[:,12,::]], \n",
    "                             Y_PRED_mask_11[:,13,::][~y_boolmat_test[:,13,::]]], axis=0)\n",
    "\n",
    "Y_PRED_LAG_4 = np.concatenate([Y_PRED_mask_1[:,4,::][~y_boolmat_test[:,4,:]], \n",
    "                             Y_PRED_mask_2[:,5,::][~y_boolmat_test[:,5,:]], \n",
    "                             Y_PRED_mask_3[:,6,::][~y_boolmat_test[:,6,::]], \n",
    "                             Y_PRED_mask_4[:,7,::][~y_boolmat_test[:,7,:]],\n",
    "                             Y_PRED_mask_5[:,8,::][~y_boolmat_test[:,8,::]], \n",
    "                             Y_PRED_mask_6[:,9,::][~y_boolmat_test[:,9,::]], \n",
    "                             Y_PRED_mask_7[:,10,::][~y_boolmat_test[:,10,::]], \n",
    "                             Y_PRED_mask_8[:,11,::][~y_boolmat_test[:,11,::]],\n",
    "                             Y_PRED_mask_9[:,12,::][~y_boolmat_test[:,12,::]], \n",
    "                             Y_PRED_mask_10[:,13,::][~y_boolmat_test[:,13,::]]], axis=0)\n",
    "\n",
    "Y_PRED_LAG_5 = np.concatenate([Y_PRED_mask_1[:,5,::][~y_boolmat_test[:,5,:]], \n",
    "                             Y_PRED_mask_2[:,6,::][~y_boolmat_test[:,6,:]], \n",
    "                             Y_PRED_mask_3[:,7,::][~y_boolmat_test[:,7,::]], \n",
    "                             Y_PRED_mask_4[:,8,::][~y_boolmat_test[:,8,:]],\n",
    "                             Y_PRED_mask_5[:,9,::][~y_boolmat_test[:,9,::]], \n",
    "                             Y_PRED_mask_6[:,10,::][~y_boolmat_test[:,10,::]], \n",
    "                             Y_PRED_mask_7[:,11,::][~y_boolmat_test[:,10,::]], \n",
    "                             Y_PRED_mask_8[:,12,::][~y_boolmat_test[:,11,::]],\n",
    "                             Y_PRED_mask_9[:,13,::][~y_boolmat_test[:,12,::]]], axis=0)\n",
    "\n",
    "Y_PRED_LAG_5 = np.concatenate([Y_PRED_mask_1[:,5,::][~y_boolmat_test[:,5,:]], \n",
    "                             Y_PRED_mask_2[:,6,::][~y_boolmat_test[:,6,:]], \n",
    "                             Y_PRED_mask_3[:,7,::][~y_boolmat_test[:,7,::]], \n",
    "                             Y_PRED_mask_4[:,8,::][~y_boolmat_test[:,8,:]],\n",
    "                             Y_PRED_mask_5[:,9,::][~y_boolmat_test[:,9,::]], \n",
    "                             Y_PRED_mask_6[:,10,::][~y_boolmat_test[:,10,::]], \n",
    "                             Y_PRED_mask_7[:,11,::][~y_boolmat_test[:,11,::]], \n",
    "                             Y_PRED_mask_8[:,12,::][~y_boolmat_test[:,12,::]],\n",
    "                             Y_PRED_mask_9[:,13,::][~y_boolmat_test[:,13,::]]], axis=0)\n",
    "\n",
    "Y_PRED_LAG_6 = np.concatenate([Y_PRED_mask_1[:,6,::][~y_boolmat_test[:,6,:]], \n",
    "                             Y_PRED_mask_2[:,7,::][~y_boolmat_test[:,7,:]], \n",
    "                             Y_PRED_mask_3[:,8,::][~y_boolmat_test[:,8,::]], \n",
    "                             Y_PRED_mask_4[:,9,::][~y_boolmat_test[:,9,:]],\n",
    "                             Y_PRED_mask_5[:,10,::][~y_boolmat_test[:,10,::]], \n",
    "                             Y_PRED_mask_6[:,11,::][~y_boolmat_test[:,11,::]], \n",
    "                             Y_PRED_mask_7[:,12,::][~y_boolmat_test[:,12,::]], \n",
    "                             Y_PRED_mask_8[:,13,::][~y_boolmat_test[:,13,::]]], axis=0)\n",
    "\n",
    "Y_PRED_LAG_7 = np.concatenate([Y_PRED_mask_1[:,7,::][~y_boolmat_test[:,7,:]], \n",
    "                             Y_PRED_mask_2[:,8,::][~y_boolmat_test[:,8,:]], \n",
    "                             Y_PRED_mask_3[:,9,::][~y_boolmat_test[:,9,::]], \n",
    "                             Y_PRED_mask_4[:,10,::][~y_boolmat_test[:,10,:]],\n",
    "                             Y_PRED_mask_5[:,11,::][~y_boolmat_test[:,11,::]], \n",
    "                             Y_PRED_mask_6[:,12,::][~y_boolmat_test[:,12,::]], \n",
    "                             Y_PRED_mask_7[:,13,::][~y_boolmat_test[:,13,::]]], axis=0)\n",
    "                                      \n",
    "## LAG ROC ##\n",
    "\n",
    "# Day 1 Lag\n",
    "print(roc_auc_score(Y_TEST_LAG_1, Y_PRED_LAG_1))\n",
    "# Day 2 Lag\n",
    "print(roc_auc_score(Y_TEST_LAG_2, Y_PRED_LAG_2))\n",
    "# # Day 3 Lag\n",
    "print(roc_auc_score(Y_TEST_LAG_3, Y_PRED_LAG_3))\n",
    "# Day 4 Lag\n",
    "print(roc_auc_score(Y_TEST_LAG_4, Y_PRED_LAG_4))\n",
    "# Day 5 Lag\n",
    "print(roc_auc_score(Y_TEST_LAG_5, Y_PRED_LAG_5))\n",
    "# Day 6 Lag\n",
    "print(roc_auc_score(Y_TEST_LAG_6, Y_PRED_LAG_6))\n",
    "# Day 6 Lag\n",
    "print(roc_auc_score(Y_TEST_LAG_7, Y_PRED_LAG_7))  \n",
    "\n",
    "confusion_matrix(Y_TEST_LAG_1, np.around(Y_PRED_LAG_1))\n",
    "\n",
    "## 100% Training Data with 1 day lag ##\n",
    "TN, FP, FN, TP = confusion_matrix(Y_TEST_LAG_1, np.around(Y_PRED_LAG_1)).ravel()\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"PPV for full model w/ 1 day lag is {0}\".format(PPV))\n",
    "CR = classification_report(Y_TEST_LAG_1, np.around(Y_PRED_LAG_1))\n",
    "\n",
    "print(\"Sensitivity for full model w/ 1 day lag is {0}\".format(CR.split('\\n')[3].split()[2]))\n",
    "# classification_report(Y_TEST[~y_boolmat_test], np.around(Y_PRED_mask_0[~y_boolmat_test]))\n",
    "\n",
    "print(classification_report(Y_TEST_LAG_1, np.around(Y_PRED_LAG_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fpr_mask_1, tpr_mask_1, thresholds_mask_1) = roc_curve(Y_TEST_LAG_1, Y_PRED_LAG_1)\n",
    "(fpr_mask_2, tpr_mask_2, thresholds_mask_2) = roc_curve(Y_TEST_LAG_2, Y_PRED_LAG_2)\n",
    "(fpr_mask_3, tpr_mask_3, thresholds_mask_3) = roc_curve(Y_TEST_LAG_3, Y_PRED_LAG_3)\n",
    "(fpr_mask_4, tpr_mask_4, thresholds_mask_4) = roc_curve(Y_TEST_LAG_4, Y_PRED_LAG_4)\n",
    "(fpr_mask_5, tpr_mask_5, thresholds_mask_5) = roc_curve(Y_TEST_LAG_5, Y_PRED_LAG_5)\n",
    "(fpr_mask_6, tpr_mask_6, thresholds_mask_6) = roc_curve(Y_TEST_LAG_6, Y_PRED_LAG_6)\n",
    "(fpr_mask_7, tpr_mask_7, thresholds_mask_7) = roc_curve(Y_TEST_LAG_7, Y_PRED_LAG_7)\n",
    "\n",
    "fpr_tprs = [(fpr_mask_1, tpr_mask_1), (fpr_mask_2, tpr_mask_2), (fpr_mask_3, tpr_mask_3), (fpr_mask_4, tpr_mask_4),\n",
    "            (fpr_mask_5, tpr_mask_5), (fpr_mask_6, tpr_mask_6), (fpr_mask_7, tpr_mask_7), (fpr_mask_8, tpr_mask_8),\n",
    "            (fpr_mask_9, tpr_mask_9), (fpr_mask_10, tpr_mask_10), (fpr_mask_11, tpr_mask_11), (fpr_mask_12, tpr_mask_12), \n",
    "            (fpr_mask_13, tpr_mask_13), (fpr_mask_0, tpr_mask_0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "for color, fpr_tpr_tuple, i in zip(np.array(color_list_reduced)[-1:0:-1], fpr_tprs, range(1,8)):\n",
    "    plt.plot(fpr_tpr_tuple[0], fpr_tpr_tuple[1], label='{0} Day Lag'.format(i), color=color)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.axhline(0, color='black')\n",
    "plt.axvline(0, color='black')\n",
    "legend = plt.legend(loc=\"lower right\", prop={'size': 10}, bbox_to_anchor=(1.29, 0.05))\n",
    "plt.savefig('./figures/{0}_lagged_roc_curves_Fig_2.eps'.format(target), format='eps',\n",
    "             dpi=300, facecolor='white', transparent=True, bbox_extra_artists=(legend,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "## FIGURE 3 ##\n",
    "##############\n",
    "\n",
    "## GET HEATMAPS FOR ALL INCIDENTS AVERAGE ##\n",
    "\n",
    "plt.figure(figsize = (8,20))\n",
    "\n",
    "sns.set(font_scale = 0.5)\n",
    "\n",
    "heatmap(np.nanmean(activations,axis=0).T[arranged_indices], \n",
    "        square=False, \n",
    "        yticklabels=np.array(features)[arranged_indices],\n",
    "        cmap=my_cmap)\n",
    "plt.gcf().axes[-1].tick_params(labelsize=10)\n",
    "plt.xticks(np.arange(TIME_STEPS)+0.5, np.arange(TIME_STEPS), fontsize=15) #, rotation=45,)\n",
    "plt.xlabel('Day', fontsize=15)\n",
    "plt.ylabel('Features', fontsize=20)\n",
    "plt.savefig('./figures/heatmap_{0}_med_ranked_average_activation_Figure_3.eps'.format(target), \n",
    "            format='eps', dpi=300, bbox_inches='tight')\n",
    "\n",
    "## MAKE THE BARPLOT THAT GOES ON TOP OF THE HEATMAP ##\n",
    "## THE ATTENTION ON EVERY TIME STEP AVERAGED OVER FEATURES ##\n",
    "\n",
    "plt.figure(figsize = (8,4)) \n",
    "sns.set(style=\"white\")\n",
    "y_vector = np.nanmean(np.nanmean(activations,axis=0).squeeze(), axis=1)\n",
    "print('There is a {0} % change between day 0 and 1'.format((y_vector[1] - y_vector[0])/float(y_vector[0])))\n",
    "color_rank = np.argsort(np.argsort(y_vector))\n",
    "plot = sns.barplot(x=list(range(14)), y=np.nanmean(np.nanmean(activations,axis=0).squeeze(), axis=1), \n",
    "                    palette=np.array(color_list)[color_rank])\n",
    "plot.set(xticklabels=[]) \n",
    "plot.set(yticklabels=[])\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "plt.savefig('./figures/heatmap_{0}_med_ranked_average_barplot_Figure_3.eps'.format(target), \n",
    "            format='eps', dpi=300, bbox_inches='tight')\n",
    "\n",
    "## IDENTIFY MOST IMPORTANT FEATURE AT EVERY TIME STEP ##\n",
    "\n",
    "plt.figure(figsize = (8,4)) \n",
    "sns.set(style=\"white\")\n",
    "y_vector = np.nanmax(np.nanmean(activations, axis=0).T[arranged_indices], axis=0)\n",
    "color_rank = np.argsort(np.argsort(y_vector))\n",
    "plot = sns.barplot(x=list(range(14)), y=np.nanmax(np.nanmean(activations, axis=0).T[arranged_indices], axis=0), \n",
    "                    palette=np.array(color_list)[color_rank])\n",
    "plt.xlabel('Day', fontsize=15)\n",
    "plt.ylabel('Feature Activation', fontsize=20)\n",
    "sns.despine()# left=True, bottom=True)\n",
    "\n",
    "plt.savefig('./figures/{0}_highest_feature_activation_by_timestep_barplot_Figure_3.eps'.format(target), \n",
    "            format='eps', dpi=300, bbox_inches='tight')\n",
    "\n",
    "## list of features by day that these activations correspond to ##\n",
    "\n",
    "np.nanargmax(np.nanmean(activations, axis=0).T[arranged_indices], axis=0)\n",
    "print(np.array(features)[arranged_indices][np.nanargmax(np.nanmean(activations, axis=0).T[arranged_indices], \n",
    "                                                     axis=0)])\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intrahospital_incidents():\n",
    "    IHI_keys =  np.where(np.nansum(Y_TEST.squeeze(), axis=1) > 1)[0]\n",
    "    for i in IHI_keys:\n",
    "        predictions = Y_PRED_mask_0[i][~y_boolmat_test[i].squeeze()].squeeze()\n",
    "        ground_truth = Y_TEST[i].squeeze()[~y_boolmat_test[i].squeeze()].squeeze()\n",
    "        acc = accuracy_score(np.around(predictions), ground_truth)\n",
    "        criteria = (acc > .9 and \n",
    "#                    np.around(predictions[0]) == 0 and\n",
    "                    (np.add(ground_truth, np.around(predictions)) == 2).any()  and\n",
    "                    (ground_truth[0] == 0) and\n",
    "                    (np.sum(ground_truth[0:2]) == 0) and\n",
    "#                    (np.sum(ground_truth) > 1) and\n",
    "                    ground_truth.shape[0] == 14)\n",
    "        if criteria:\n",
    "            print(\"Person {0} with IHI\".format(i))\n",
    "            print('Ground Truth')\n",
    "            print(ground_truth)\n",
    "            print('Predicted Sequence')\n",
    "            print(np.around(predictions))\n",
    "            print('\\n')\n",
    "        \n",
    "find_intrahospital_incidents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target == 'MI':\n",
    "    patient_num = 3947\n",
    "elif target == 'SEPSIS':\n",
    "    patient_num = 927\n",
    "elif target == 'VANCOMYCIN':\n",
    "    patient_num = 1372 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_heatmap(patient_num, savefig=False, target=None):\n",
    "    \n",
    "        if target == None:\n",
    "            raise Exception('Specify Target')\n",
    "            \n",
    "        print('\\n')\n",
    "        print('Visualize Inputs')\n",
    "        print('Ground Truth')\n",
    "        ground_truth = Y_TEST[patient_num].squeeze()[~y_boolmat_test[patient_num].squeeze()]\n",
    "        print(ground_truth)\n",
    "        print('Predicted Sequence')\n",
    "        predictions = Y_PRED_mask_0[patient_num].squeeze()[~y_boolmat_test[patient_num].squeeze()]\n",
    "        print(np.around(predictions))\n",
    "        \n",
    "        if target == 'MI':\n",
    "            color_list_barplot = sns.color_palette(\"Reds\", ground_truth.shape[0])\n",
    "        elif target == 'SEPSIS':\n",
    "            color_list_barplot = sns.cubehelix_palette(ground_truth.shape[0], start=2, rot=0, dark=0.25, light=.95)\n",
    "        elif target == 'VANCOMYCIN':\n",
    "            color_list_barplot = sns.cubehelix_palette(ground_truth.shape[0])\n",
    "        \n",
    "        print('Individual Heatmap')\n",
    "        plt.figure(figsize = (8,20))\n",
    "        sns.set(font_scale = 0.5)\n",
    "        \n",
    "    #    activations_map = np.nanmean(activations,axis=0)/(np.nanmax(np.nanmean(activations, axis=0), axis=1))[:,None]\n",
    "        activations_map = activations[patient_num]/np.nanmax(activations[patient_num,::,::], axis=1)[:,None]\n",
    "        heatmap(activations[patient_num].T[arranged_indices], \n",
    "                       square=False, \n",
    "#                      vmin=np.amin(activations[patient_num,:,:]),\n",
    "#                      vmax=np.amax(activations[patient_num,:,:]),\n",
    "                     yticklabels=np.array(features)[arranged_indices], cmap=my_cmap)\n",
    "        plt.gcf().axes[-1].tick_params(labelsize=10) \n",
    "        plt.xticks(np.arange(TIME_STEPS)+0.5, np.arange(TIME_STEPS), fontsize=15)\n",
    "        plt.yticks(fontsize=8)\n",
    "        plt.xlabel('Day', fontsize=20)\n",
    "        plt.ylabel('Features', fontsize=20)\n",
    "        plt.xticks(np.arange(TIME_STEPS)+0.5, np.arange(TIME_STEPS), fontsize=15) #, rotation=45,)\n",
    "        \n",
    "        if savefig:\n",
    "            plt.savefig('./figures/heatmap_{0}_patient_{1}.eps'.format(target, patient_num), \n",
    "                        format='eps', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        rel_vector = np.nanmean(activations[patient_num,::,::].T.squeeze(), axis=0)\n",
    "        rel_vector = rel_vector[~y_boolmat_test[patient_num].squeeze()]\n",
    "        color_order = np.argsort(rel_vector, axis=0)\n",
    "        color_order_order = np.argsort(color_order)\n",
    "\n",
    "        plt.figure(figsize = (8,4)) \n",
    "        sns.set(style=\"white\")\n",
    "        plot = sns.barplot(x=np.arange(14)[~y_boolmat_test[patient_num].squeeze()], y=rel_vector, \n",
    "                           palette=np.array(color_list_barplot)[color_order_order])\n",
    "        plot.set(xticklabels=[]) \n",
    "        plot.set(yticklabels=[])\n",
    "        sns.despine(left=True, bottom=True)\n",
    "        \n",
    "        print('Patient Features Heatmap')\n",
    "        if savefig:\n",
    "            plt.savefig('./figures/barplot_for_heatmap_{0}_patient_{1}.eps'.format(target, patient_num), \n",
    "                        format='eps', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        plt.figure(figsize= (8,20))\n",
    "        sns.set(font_scale = 0.5)\n",
    "        activations_map = X_TEST[patient_num,::,::]/np.nanmax(X_TEST[patient_num,::,::], axis=0) #[:,None]\n",
    "        heatmap(X_TEST[patient_num,::,::].T[arranged_indices], square=False, \n",
    "                yticklabels=np.array(features)[arranged_indices], \n",
    "                cmap=my_cmap) #, cbar_kws={'ticks':[]})\n",
    "        plt.gcf().axes[-1].tick_params(labelsize=10)\n",
    "        plt.xticks(np.arange(TIME_STEPS)+0.5, np.arange(TIME_STEPS), fontsize=15) #, rotation=45,)\n",
    "        plt.yticks(fontsize=8)\n",
    "        plt.xlabel('Day', fontsize=20)\n",
    "        plt.ylabel('Features', fontsize=20)\n",
    "        plt.xticks(np.arange(TIME_STEPS)+0.5, np.arange(TIME_STEPS), fontsize=15) #, rotation=45,)\n",
    "        if savefig:\n",
    "            plt.savefig('./figures/features_heatmap_{0}_patient_{1}.eps'.format(target, patient_num), \n",
    "                        format='eps', dpi=300, bbox_inches='tight')\n",
    "            \n",
    "        rel_vector = np.nanmean(X_TEST[patient_num,::,::].T.squeeze(), axis=0)[~y_boolmat_test[patient_num].squeeze()]\n",
    "        color_order = np.argsort(rel_vector, axis=0)\n",
    "        color_order_order = np.argsort(color_order)\n",
    "\n",
    "        plt.figure(figsize = (8,4)) \n",
    "        sns.set(style=\"white\")\n",
    "        plot = sns.barplot(x=np.arange(14)[~y_boolmat_test[patient_num].squeeze()], y=rel_vector, \n",
    "                           palette=np.array(color_list_barplot)[color_order_order])\n",
    "        plot.set(xticklabels=[]) \n",
    "        plot.set(yticklabels=[])\n",
    "        sns.despine(left=True, bottom=True)\n",
    "        if savefig:\n",
    "            plt.savefig('./figures/barplot_features_heatmap_{0}_patient_{1}.eps'.format(target, patient_num), \n",
    "                        format='eps', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example use of patient_heatmap\n",
    "\n",
    "patient_heatmap(patient_num, savefig=True, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the top activations for that day, the day before, the day before ##\n",
    "\n",
    "def features_driving_incident(patient_num, savefig=False):\n",
    "    \n",
    "    plt.figure(figsize = (8,4)) \n",
    "    sns.set(style=\"white\")\n",
    "    \n",
    "    if np.where(Y_TEST[patient_num] == 1)[0][0] == 1:\n",
    "        day_zero = 1\n",
    "        day_neg_one = 0\n",
    "        days = np.array([day_neg_one, day_zero])\n",
    "        days_string = ['Day -1', 'Day 0']\n",
    "    else:\n",
    "        assert np.where(Y_TEST[patient_num] == 1)[0][0] >= 2\n",
    "        day_zero = np.where(Y_TEST[patient_num] == 1)[0][0]\n",
    "        day_neg_one = day_zero - 1\n",
    "        day_neg_two = day_zero - 2\n",
    "        days = np.array([day_neg_two, day_neg_one, day_zero])\n",
    "        days_string = ['Day -2', 'Day -1', 'Day 0']\n",
    "        \n",
    "    y_vector = np.nanmax(activations[patient_num], axis=1) #[days]\n",
    "    print(y_vector)\n",
    "    print(np.nansum(y_vector))\n",
    "    color_rank = np.argsort(np.argsort(y_vector))\n",
    "    plot = sns.barplot(x=days_string, y=y_vector[days], \n",
    "                       palette=np.array(color_list)[color_rank][days])\n",
    "    plt.ylabel('Feature Activation', fontsize=20)\n",
    "        #plot.set(xticklabels=[]) \n",
    "        #plot.set(yticklabels=[])\n",
    "    sns.despine() # left=True, bottom=True)\n",
    "\n",
    "    if savefig:\n",
    "        plt.savefig('./figures/max_activation_pre_incident_barplot_Figure_4_{0}_patient_{1}.eps'.format(target, patient_num), \n",
    "             format='eps', dpi=300, bbox_inches='tight')\n",
    "                   \n",
    "    ## list of features by day that these activations correspond to ##\n",
    "\n",
    "    print(np.array(features)[np.nanargmax(activations[patient_num], axis=1)][days])\n",
    "    print(np.nanmax(activations[patient_num], axis=1)[days])\n",
    "    \n",
    "#####\n",
    "    \n",
    "features_driving_incident(patient_num, savefig=True)\n",
    "    \n",
    "#####    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(activations[patient_num].shape)\n",
    "\n",
    "print(activations[patient_num].T[features.index('phenylephrine'),1])\n",
    "\n",
    "#activations[patient_num][list(np.array(features)[arranged_indices]).index('levothyroxine'),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIGURE 4 ##\n",
    "\n",
    "def predictions_labels_palplot(patient_num, savefig=False):\n",
    "    \n",
    "    color_list_gt = np.array(color_list.copy())\n",
    "    color_list_gt[Y_TEST[patient_num].squeeze() == 1] = color_list_gt[-1]\n",
    "    color_list_gt[Y_TEST[patient_num].squeeze() == 0] = [0,0,0]       \n",
    "    sns.palplot(color_list_gt)\n",
    "    plt.ylabel('Ground\\n    Truth     ', fontsize=15, rotation='horizontal', labelpad=45) #.set_rotation(0)\n",
    "    \n",
    "    if savefig:\n",
    "        plt.savefig('./figures/{0}_GT_labels_Figure_4.eps'.format(target), format='eps',\n",
    "                dpi=300, facecolor='white', transparent=True, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
    "\n",
    "    color_list_pred = np.array(color_list.copy())\n",
    "    color_list_pred[np.around(Y_PRED_mask_0[patient_num].squeeze()) == 1] = color_list_pred[-1]\n",
    "    color_list_pred[np.around(Y_PRED_mask_0[patient_num].squeeze()) == 0] = [0,0,0]\n",
    "    sns.palplot(color_list_pred)\n",
    "    plt.ylabel('Predicted\\n Sequence', fontsize=15, rotation='horizontal', labelpad=45)\n",
    "    if savefig:\n",
    "        plt.savefig('./figures/{0}_PRED_labels_Figure_4.eps'.format(target), format='eps',\n",
    "                   dpi=300, facecolor='white', transparent=True, bbox_extra_artists=(legend,), \n",
    "                    bbox_inches='tight')\n",
    "    \n",
    "predictions_labels_palplot(patient_num, savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
